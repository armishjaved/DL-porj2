{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tHuUINZkBhAK",
    "outputId": "817c13d6-c064-416e-b9ba-b742ce6c6f9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QEXIyN_5Yg5K"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import RobertaModel, RobertaTokenizer, TrainingArguments, Trainer, DataCollatorWithPadding, RobertaForSequenceClassification\n",
    "from peft import LoraConfig, get_peft_model, PeftModel, TaskType\n",
    "from datasets import load_dataset, Dataset, ClassLabel\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 552,
     "referenced_widgets": [
      "f06c07e80a104c4c8736d2139a9f9491",
      "2f4d0592e86d4d2eb4f7e513ce9f9170",
      "0e6b6e394a154927aa6358126b4e72e5",
      "7f30ef55c16c438bbe25e1992e165ab0",
      "cff08217c0584c6c93debd3e9c912761",
      "dec0c79ce7fd476a9e35a25f837a2de8",
      "80a4c0373b974df294a2f4b7fbfa5bb1",
      "edf4aea0e710485a8534d0943df4b9d2",
      "00d9e209ac614466b1630dde525b6c28",
      "7279569dfee6476faa62224215224adb",
      "b530a432a1574f9c9a8729435a445fb7",
      "8c4556bb02b740e29a51c303574cf1e6",
      "d2a950c400b748368108a941371d927f",
      "cdf64539424b4e6d9a4d839015f7bd80",
      "f0b4cabd000c48cd9525ee7c0609496d",
      "8603234d1b38490cb3851f73d7e37fd3",
      "e519854401334dc5ad23f9f7b62e9946",
      "90eb53ac0e0841b5896d037895e02540",
      "6f4a32656c0c4369b5e75e8a7cef5d03",
      "cc5df758e675412dbed79bcfc1c21b95",
      "b29f7c522fef4abba878bf559e1e84ba",
      "ea98616e5a18456bb737052967953b8f",
      "b0da20bd006b4ebb825300d524d386d8",
      "c2e140b3d7ba4bf5bb8c98fd7d5c177f",
      "903a57f93f124020b13d0f66a33b599d",
      "df3c2f17675340c28a30eb6cd75a3283",
      "a7cb902b2a89445abb1b526914d10794",
      "574aa7c83a694f1fb57fa1ac4bc2fe07",
      "f6544545d489456cbe14a3fd13f5ba55",
      "c4ab3dd1aa514110a7bfa5068ec21c74",
      "d0290a288f714ae2832d75321dbb44af",
      "1a733423704a4c528e570f5b5ea4d7c1",
      "2f513cda087143eba655a9e76435931d",
      "3a480929aa514d47a173396ca6a41aed",
      "b75585019a2a4a1c96799e510ef9cbf1",
      "c40886c8e98440f399237b720e79e8bc",
      "531b0355274a4f7284f751c7f1b2c8e9",
      "f120c552e36942eeb8d91a9e1ca06e80",
      "0952b55eb0d74fe0a58e7e65070e3a60",
      "fa41d47f39cf46a1974678c5d4f7be18",
      "0d2ca8a9ee164cb29db80fdb1bb541e2",
      "471fbc01cd3e4872a15d6a527c27c56b",
      "bb9b28590a5a4c2ca4021ff8b257c468",
      "0af76de31d6d463bb24174628ea51565",
      "85ce7cdc97114f039daf316c2f95ef10",
      "e40565a4f1b6404ea86005d22369527d",
      "a103941602c5402585d1ee2dab5828fc",
      "9ccf08359a6a4e8a8a8f6b50adf1b492",
      "f53c20dcb8f54ce69961881eee7dc606",
      "2582e82522454aa688a895d105b62116",
      "aa97f08d6dd342209700ced9e63b0c01",
      "4a7a980ef7d942e7bdc25e7a929a2993",
      "0017a482c2f7484b9865b314363ce4fc",
      "32ff8e69b26747b1b689c82d6114c5f7",
      "3deee8646abf49128bbc1fa2dbe7ee07",
      "29ee6ab6d884459bb70111c38ff9cae6",
      "cb9ba19b4f37429b83b4ada898735f23",
      "28f50bb22b634b1cbb3546cd4da0f667",
      "18fb9f57e6aa4c91bb9815be83c94ac6",
      "0d94ddb69a644c5c8b9bb5398b3f9f63",
      "c7e8c54e2d3f4e499aeb8f29e56c0cdc",
      "dd569fbe563e44a1b1a10d3103bbdb37",
      "af63f51fa5454ad897990cf3eebfc0ee",
      "0f43e4cfdbf64f6f96a785372bee9bcb",
      "f1ba044891a54a219d4098cae026f334",
      "53ee04f64caa408e97329e879afebd67",
      "6d0c8b556115480a86924c3e469e2c33",
      "7d683d5ed90147a983e4250b02dc1f68",
      "71b6b1add6bd47e9bfdd005eb2f232d0",
      "ddb493f678c5492cbfb0580920c301f9",
      "3a89cd87af4a40a58a4139bbef8854d0",
      "1d0d9d2855c44f53b27019ec1f2ea91a",
      "e4910ec4dc3b4710ac9a2dedac293e93",
      "1838a3127f93486cb1e79344a26d4611",
      "6ed5ce8e9ab041beb4f46fbea7430835",
      "f71e3f82121c4546a79061bde94ab961",
      "02265e37c25047679be016a7454375e5",
      "194a1a6177114a6b90bc1c69e886b598",
      "18d1b13ef30e4b1d9a6dccdffa2e4cef",
      "77ab642ad24249799b5620a570984205",
      "4ba7e5768e9342c8b8094a261c3207b4",
      "90108dc1cfda4575881692077a578842",
      "786706ebe7b3453cab9f928edb1956ef",
      "28cf0f3fffb7481ead100b308abf5844",
      "fa94d8d9609d4c0b9efe78c30a4f932a",
      "008ea1ee3c5143df8032a0dae1bf973f",
      "93a65b5a4deb4f048c9bcf4dcb413fa4",
      "e6d9ae0f37fd43e88237db063dff7771",
      "e9014a24e8b746bca8c25b86e7da7cd5",
      "7feb840f54ac4c439a6757dd886b1107",
      "76f686e06ed24f269b508899be8b71b8",
      "7faabfb847f44b568e7d2383efd1b46d",
      "53d6809bb3fd4c90bbcc4a4f7a506c72",
      "2862e941157c42c1b80e79f5e34413fc",
      "09066cc201df473c991a2c3eccf696ec",
      "1d84dd2cbf45414c8fdfa57a614929da",
      "e0180edd2c08469099d9e3612ccdac0a",
      "9a2322afbb904132bfbde70ccf09fb3b",
      "af48441b6dcb42838f0cb971e480dc0f",
      "7d307276584b4fd2acc99b49ec6ae519",
      "c092f1914d904e14b810305074d30e29",
      "0c41fae885964e15aabd95effb429203",
      "51acf02b692142d6815ae4f0c509cab8",
      "cfa1f890a4c1473689508b3f8f28b63c",
      "6f46712bcd0a4cdaafcf7542a4db18d0",
      "5ef0520d15f94eb991f86d10a6966d32",
      "93cb636afef24c28803a0c83107a89db",
      "bb44b57e405442468a54b62b9b161b49",
      "45e55603f9bd4318ac84e0106d31f02a",
      "b886308d253f4e08bc8439f89f0c257c",
      "0feafc52866e4c4d816bc10228488d49",
      "8486f3b1766c479e9dd911fa4bd8693c",
      "ce54dd587246452d8c0ec9cd6dac5830",
      "23366abce4ab4ac1a6452a9155f43f74",
      "d3be0b8556e94de9b0c7b6d936898b64",
      "982cd544da624dd48f4a27470c566d93",
      "6e1596e4ac074235b43906bda4428e8c",
      "3abcf5bd4f75485b845b6256483803f0",
      "27f1a1c36a6644638241a58245759d18",
      "349ba87c221f4ee8bed0cfa010c401dd",
      "198c79af6296427eae381797e9b534c0"
     ]
    },
    "id": "KcJGdk0WYu_0",
    "outputId": "525d059b-d248-4403-eb16-b5ff24973b8d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06c07e80a104c4c8736d2139a9f9491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4556bb02b740e29a51c303574cf1e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0da20bd006b4ebb825300d524d386d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a480929aa514d47a173396ca6a41aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ce7cdc97114f039daf316c2f95ef10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ee6ab6d884459bb70111c38ff9cae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0c8b556115480a86924c3e469e2c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194a1a6177114a6b90bc1c69e886b598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9014a24e8b746bca8c25b86e7da7cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d307276584b4fd2acc99b49ec6ae519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0feafc52866e4c4d816bc10228488d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load tokenizer and model\n",
    "base_model = 'roberta-base'\n",
    "\n",
    "dataset = load_dataset('ag_news', split='train')\n",
    "tokenizer = RobertaTokenizer.from_pretrained(base_model)\n",
    "\n",
    "def preprocess(examples):\n",
    "    tokenized = tokenizer(examples['text'], truncation=True, padding=True)\n",
    "    return tokenized\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess, batched=True, remove_columns=[\"text\"])\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tZaRKXFzYxvi",
    "outputId": "56b41ad5-c305-4f39-a258-c8813efe0d44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of labels: 4\n",
      "the labels: ['World', 'Sports', 'Business', 'Sci/Tech']\n"
     ]
    }
   ],
   "source": [
    "# Extract the number of classes and their names\n",
    "num_labels = dataset.features['label'].num_classes\n",
    "class_names = dataset.features[\"label\"].names\n",
    "print(f\"number of labels: {num_labels}\")\n",
    "print(f\"the labels: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TxfNWUb7Yz2h"
   },
   "outputs": [],
   "source": [
    "# Create an id2label mapping\n",
    "id2label = {i: label for i, label in enumerate(class_names)}\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140,
     "referenced_widgets": [
      "35f03c25beaf4c5bad1213835cdf0780",
      "f6fc50a1b72b4ac19a6f7f87926a56e8",
      "927d791429d94a9c98947f06971ead2e",
      "ca1179f62b5741f3bcc49848175e0052",
      "b3d7364994b04daab584bea735caf082",
      "c9f42c8e455744dc93c45f91b3bebda0",
      "2c1eafc026464159965f85bb86dc0a3d",
      "ec6853cedc3e417c8632b71c00a2b6d6",
      "ca947162015445929b8837c50867329b",
      "fdeb89f0e0114cbfb946575806244a5a",
      "321279cd683a497eb91c1b4937bdc210"
     ]
    },
    "id": "6u1veafVY2eP",
    "outputId": "a21a5353-5e35-475d-a710-e65990a40e3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f03c25beaf4c5bad1213835cdf0780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    base_model,\n",
    "    id2label=id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_fB3hVnaY4c1",
    "outputId": "a844dee0-5bd6-44da-f7a0-cc2e10621486"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 119360\n",
      "Evaluation samples: 640\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset\n",
    "split_datasets = tokenized_dataset.train_test_split(test_size=640, seed=42, stratify_by_column=\"labels\")\n",
    "train_dataset = split_datasets['train']\n",
    "eval_dataset = split_datasets['test']\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Evaluation samples: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eoVosrn7Y6b2",
    "outputId": "6ae8c08b-5bcf-4039-ccbd-4bb50ab79080"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution in training set:\n",
      "0    29840\n",
      "1    29840\n",
      "2    29840\n",
      "3    29840\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Examine class distribution to ensure balance\n",
    "label_counts = pd.Series(train_dataset['labels']).value_counts()\n",
    "print(f\"Label distribution in training set:\\n{label_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "A5D3qz1XY8bc"
   },
   "outputs": [],
   "source": [
    "# PEFT Config - Enhanced configuration for better performance\n",
    "peft_config = LoraConfig(\n",
    "    r=7,  # Chosen to stay under 1M parameter limit\n",
    "    lora_alpha=32,  # Higher alpha for stronger adaptation\n",
    "    lora_dropout=0.1,  # Added dropout for regularization\n",
    "    bias=\"none\",\n",
    "    # Target attention matrices for comprehensive adaptation\n",
    "    target_modules=[\"query\", \"key\", \"value\"],\n",
    "    task_type=TaskType.SEQ_CLS,  # Explicitly set the task type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hTxcfwgQY_or"
   },
   "outputs": [],
   "source": [
    "# Create the PEFT model by applying LoRA to the base model\n",
    "peft_model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9EMbMD6aZBil"
   },
   "outputs": [],
   "source": [
    "# Function to count trainable parameters to ensure we stay under 1 million\n",
    "def count_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    return trainable_params, all_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MbgtnMZgZDFb",
    "outputId": "dfccd465-600b-4c1f-ad99-7417948785bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 980,740\n",
      "All parameters: 125,629,448\n",
      "Under 1M parameter limit: Yes\n"
     ]
    }
   ],
   "source": [
    "# Check if we're under the parameter limit\n",
    "trainable_params, all_params = count_trainable_parameters(peft_model)\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"All parameters: {all_params:,}\")\n",
    "print(f\"Under 1M parameter limit: {'Yes' if trainable_params < 1_000_000 else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RBEskxGrZHWm",
    "outputId": "bd6e91e2-c317-4066-e416-33726b2ec154"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEFT Model\n",
      "trainable params: 980,740 || all params: 125,629,448 || trainable%: 0.7807\n"
     ]
    }
   ],
   "source": [
    "print('PEFT Model')\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "qf7CG-1qZKBs"
   },
   "outputs": [],
   "source": [
    "# To track evaluation metrics during training\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    # Calculate accuracy and other metrics\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='weighted')\n",
    "    recall = recall_score(labels, preds, average='weighted')\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "LnPSho2-ZMR9"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "TrainingArguments = transformers.TrainingArguments\n",
    "\n",
    "# Setup Training args with improved settings for better performance\n",
    "output_dir = \"results\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    # report_to=None,  # Disable reporting to save resources\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,  # Evaluate more frequently\n",
    "    logging_steps=50,\n",
    "    learning_rate=2.5e-4,  # Increased learning rate for LoRA\n",
    "    num_train_epochs=3,  # Train for more epochs\n",
    "    max_steps=-1,  # Set to -1 to use num_train_epochs instead of a fixed number of steps\n",
    "    weight_decay=0.01,  # Add L2 regularization\n",
    "    per_device_train_batch_size=32,  # Increased batch size\n",
    "    per_device_eval_batch_size=64,\n",
    "    fp16=torch.cuda.is_available(),  # Use mixed precision if available\n",
    "    gradient_accumulation_steps=2,  # Accumulate gradients for stability\n",
    "    warmup_ratio=0.1,  # Add warmup steps\n",
    "    load_best_model_at_end=True,  # Save the best model\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    dataloader_num_workers=4,\n",
    "    optim=\"adamw_torch\",  # Use AdamW optimizer\n",
    "    report_to=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h1TISSAYmgpR",
    "outputId": "6838e5ca-e59c-4adf-e475-72a6efd62914"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 980,740\n",
      "All parameters: 125,629,448\n",
      "Under 1M parameter limit: Yes\n"
     ]
    }
   ],
   "source": [
    "# Check if we're under the parameter limit\n",
    "trainable_params, all_params = count_trainable_parameters(peft_model)\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"All parameters: {all_params:,}\")\n",
    "print(f\"Under 1M parameter limit: {'Yes' if trainable_params < 1_000_000 else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "-yL2iq7bZOqk"
   },
   "outputs": [],
   "source": [
    "def get_trainer(model):\n",
    "    return Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        compute_metrics=compute_metrics,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        data_collator=data_collator,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bSxoJAhJZQj_",
    "outputId": "2afa2008-0f8a-42e5-bade-fac924f110df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5595' max='5595' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5595/5595 1:24:55, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.354700</td>\n",
       "      <td>1.247783</td>\n",
       "      <td>0.790625</td>\n",
       "      <td>0.831710</td>\n",
       "      <td>0.790625</td>\n",
       "      <td>0.780132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.331400</td>\n",
       "      <td>0.316282</td>\n",
       "      <td>0.878125</td>\n",
       "      <td>0.877174</td>\n",
       "      <td>0.878125</td>\n",
       "      <td>0.877335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.279200</td>\n",
       "      <td>0.279979</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.906582</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.905852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.242200</td>\n",
       "      <td>0.275638</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.896528</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.892982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.286400</td>\n",
       "      <td>0.281385</td>\n",
       "      <td>0.918750</td>\n",
       "      <td>0.921090</td>\n",
       "      <td>0.918750</td>\n",
       "      <td>0.918397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.243700</td>\n",
       "      <td>0.242698</td>\n",
       "      <td>0.923438</td>\n",
       "      <td>0.923525</td>\n",
       "      <td>0.923438</td>\n",
       "      <td>0.923189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.229657</td>\n",
       "      <td>0.917188</td>\n",
       "      <td>0.917285</td>\n",
       "      <td>0.917188</td>\n",
       "      <td>0.916632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.236100</td>\n",
       "      <td>0.269761</td>\n",
       "      <td>0.901563</td>\n",
       "      <td>0.901811</td>\n",
       "      <td>0.901563</td>\n",
       "      <td>0.901181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.246100</td>\n",
       "      <td>0.236686</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.921965</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.921846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.193800</td>\n",
       "      <td>0.234247</td>\n",
       "      <td>0.920312</td>\n",
       "      <td>0.920727</td>\n",
       "      <td>0.920312</td>\n",
       "      <td>0.920437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.220100</td>\n",
       "      <td>0.252220</td>\n",
       "      <td>0.928125</td>\n",
       "      <td>0.928947</td>\n",
       "      <td>0.928125</td>\n",
       "      <td>0.927758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.210100</td>\n",
       "      <td>0.222727</td>\n",
       "      <td>0.918750</td>\n",
       "      <td>0.919206</td>\n",
       "      <td>0.918750</td>\n",
       "      <td>0.918474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.214400</td>\n",
       "      <td>0.225022</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.925575</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.925017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.201000</td>\n",
       "      <td>0.228734</td>\n",
       "      <td>0.920312</td>\n",
       "      <td>0.919781</td>\n",
       "      <td>0.920312</td>\n",
       "      <td>0.919633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.196600</td>\n",
       "      <td>0.208109</td>\n",
       "      <td>0.923438</td>\n",
       "      <td>0.923416</td>\n",
       "      <td>0.923438</td>\n",
       "      <td>0.923306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.197200</td>\n",
       "      <td>0.207401</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.925024</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.924957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.194800</td>\n",
       "      <td>0.207185</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.921405</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.921599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.214600</td>\n",
       "      <td>0.209509</td>\n",
       "      <td>0.926562</td>\n",
       "      <td>0.926635</td>\n",
       "      <td>0.926562</td>\n",
       "      <td>0.926430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.173500</td>\n",
       "      <td>0.232702</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.921513</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.921524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.177000</td>\n",
       "      <td>0.211271</td>\n",
       "      <td>0.928125</td>\n",
       "      <td>0.927902</td>\n",
       "      <td>0.928125</td>\n",
       "      <td>0.927947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.176500</td>\n",
       "      <td>0.214807</td>\n",
       "      <td>0.926562</td>\n",
       "      <td>0.926850</td>\n",
       "      <td>0.926562</td>\n",
       "      <td>0.926442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.178300</td>\n",
       "      <td>0.216250</td>\n",
       "      <td>0.928125</td>\n",
       "      <td>0.928125</td>\n",
       "      <td>0.928125</td>\n",
       "      <td>0.927874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.168900</td>\n",
       "      <td>0.227987</td>\n",
       "      <td>0.928125</td>\n",
       "      <td>0.928547</td>\n",
       "      <td>0.928125</td>\n",
       "      <td>0.927953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.166600</td>\n",
       "      <td>0.212204</td>\n",
       "      <td>0.926562</td>\n",
       "      <td>0.926555</td>\n",
       "      <td>0.926562</td>\n",
       "      <td>0.926536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.175700</td>\n",
       "      <td>0.192872</td>\n",
       "      <td>0.932813</td>\n",
       "      <td>0.932637</td>\n",
       "      <td>0.932813</td>\n",
       "      <td>0.932666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.187900</td>\n",
       "      <td>0.199847</td>\n",
       "      <td>0.931250</td>\n",
       "      <td>0.931881</td>\n",
       "      <td>0.931250</td>\n",
       "      <td>0.931063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.197078</td>\n",
       "      <td>0.931250</td>\n",
       "      <td>0.931484</td>\n",
       "      <td>0.931250</td>\n",
       "      <td>0.931039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.164300</td>\n",
       "      <td>0.204523</td>\n",
       "      <td>0.926562</td>\n",
       "      <td>0.926690</td>\n",
       "      <td>0.926562</td>\n",
       "      <td>0.926528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.171300</td>\n",
       "      <td>0.192461</td>\n",
       "      <td>0.932813</td>\n",
       "      <td>0.933337</td>\n",
       "      <td>0.932813</td>\n",
       "      <td>0.932787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.171700</td>\n",
       "      <td>0.190861</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.925523</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.924892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.177100</td>\n",
       "      <td>0.182864</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.929565</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.929613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.187400</td>\n",
       "      <td>0.195045</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.926824</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.924847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.190215</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.929600</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.929594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.172500</td>\n",
       "      <td>0.197081</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.935357</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.934084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.162900</td>\n",
       "      <td>0.191059</td>\n",
       "      <td>0.931250</td>\n",
       "      <td>0.931590</td>\n",
       "      <td>0.931250</td>\n",
       "      <td>0.930958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.172100</td>\n",
       "      <td>0.189151</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937187</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.176100</td>\n",
       "      <td>0.191229</td>\n",
       "      <td>0.935937</td>\n",
       "      <td>0.935540</td>\n",
       "      <td>0.935937</td>\n",
       "      <td>0.935653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.154500</td>\n",
       "      <td>0.191715</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.930231</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.929748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.159400</td>\n",
       "      <td>0.191442</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.930056</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.929681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.160400</td>\n",
       "      <td>0.193531</td>\n",
       "      <td>0.932813</td>\n",
       "      <td>0.932478</td>\n",
       "      <td>0.932813</td>\n",
       "      <td>0.932577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.159600</td>\n",
       "      <td>0.192179</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.934300</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.934251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.163600</td>\n",
       "      <td>0.184061</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.934464</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.934213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.188460</td>\n",
       "      <td>0.935937</td>\n",
       "      <td>0.935819</td>\n",
       "      <td>0.935937</td>\n",
       "      <td>0.935874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.150900</td>\n",
       "      <td>0.194783</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.929633</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.929603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.161300</td>\n",
       "      <td>0.197672</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.934348</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.934240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.195045</td>\n",
       "      <td>0.931250</td>\n",
       "      <td>0.931236</td>\n",
       "      <td>0.931250</td>\n",
       "      <td>0.931185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.132100</td>\n",
       "      <td>0.193134</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.934195</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.934271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.154200</td>\n",
       "      <td>0.192686</td>\n",
       "      <td>0.931250</td>\n",
       "      <td>0.931631</td>\n",
       "      <td>0.931250</td>\n",
       "      <td>0.931206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.158700</td>\n",
       "      <td>0.191581</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.934175</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.934171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.158100</td>\n",
       "      <td>0.192295</td>\n",
       "      <td>0.931250</td>\n",
       "      <td>0.931288</td>\n",
       "      <td>0.931250</td>\n",
       "      <td>0.931092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.159900</td>\n",
       "      <td>0.192503</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.929584</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.929564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.148400</td>\n",
       "      <td>0.189919</td>\n",
       "      <td>0.935937</td>\n",
       "      <td>0.935755</td>\n",
       "      <td>0.935937</td>\n",
       "      <td>0.935824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.146900</td>\n",
       "      <td>0.196623</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.934175</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.934171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.142900</td>\n",
       "      <td>0.191141</td>\n",
       "      <td>0.935937</td>\n",
       "      <td>0.936010</td>\n",
       "      <td>0.935937</td>\n",
       "      <td>0.935879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.155600</td>\n",
       "      <td>0.190299</td>\n",
       "      <td>0.935937</td>\n",
       "      <td>0.935779</td>\n",
       "      <td>0.935937</td>\n",
       "      <td>0.935791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed with loss: 0.2111\n",
      "Training time: 5097.36 seconds\n"
     ]
    }
   ],
   "source": [
    "# Start Training\n",
    "peft_lora_finetuning_trainer = get_trainer(peft_model)\n",
    "\n",
    "# Train the model and capture results\n",
    "result = peft_lora_finetuning_trainer.train()\n",
    "\n",
    "# Display training results\n",
    "print(f\"Training completed with loss: {result.metrics['train_loss']:.4f}\")\n",
    "print(f\"Training time: {result.metrics['train_runtime']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "FO_cPvfZZS9a"
   },
   "outputs": [],
   "source": [
    "# Inference function\n",
    "def classify(model, tokenizer, text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    inputs = tokenizer(text, truncation=True, padding=True, return_tensors=\"pt\").to(device)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs)\n",
    "\n",
    "    # Get prediction and convert to probabilities\n",
    "    logits = output.logits\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    prediction = logits.argmax(dim=-1).item()\n",
    "    confidence = probabilities[0][prediction].item()\n",
    "\n",
    "    print(f'\\nClass: {prediction}, Label: {id2label[prediction]}, Confidence: {confidence:.4f}')\n",
    "    print(f'Text: {text}')\n",
    "\n",
    "    # Show all class probabilities\n",
    "    print(\"\\nProbabilities for all classes:\")\n",
    "    for i, label in id2label.items():\n",
    "        print(f\"{label}: {probabilities[0][i].item():.4f}\")\n",
    "\n",
    "    return id2label[prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 698
    },
    "id": "dm4ah4BiZWQf",
    "outputId": "ee343b0c-492b-4a62-d817-0cb2f73ce08d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class: 0, Label: World, Confidence: 0.9990\n",
      "Text: Kederis proclaims innocence Olympic champion Kostas Kederis today left hospital ahead of his date with IOC inquisitors claiming his innocence...\n",
      "\n",
      "Probabilities for all classes:\n",
      "World: 0.9990\n",
      "Sports: 0.0006\n",
      "Business: 0.0001\n",
      "Sci/Tech: 0.0004\n",
      "\n",
      "Class: 2, Label: Business, Confidence: 0.8379\n",
      "Text: Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling band of ultra-cynics, are seeing green again.\n",
      "\n",
      "Probabilities for all classes:\n",
      "World: 0.1602\n",
      "Sports: 0.0000\n",
      "Business: 0.8379\n",
      "Sci/Tech: 0.0019\n",
      "\n",
      "Class: 3, Label: Sci/Tech, Confidence: 0.9884\n",
      "Text: Google announces new smartphone with advanced AI capabilities at annual developer conference\n",
      "\n",
      "Probabilities for all classes:\n",
      "World: 0.0020\n",
      "Sports: 0.0000\n",
      "Business: 0.0095\n",
      "Sci/Tech: 0.9884\n",
      "\n",
      "Class: 3, Label: Sci/Tech, Confidence: 0.9445\n",
      "Text: Scientists discover potential cure for cancer in rainforest plant, clinical trials to begin next year\n",
      "\n",
      "Probabilities for all classes:\n",
      "World: 0.0500\n",
      "Sports: 0.0000\n",
      "Business: 0.0055\n",
      "Sci/Tech: 0.9445\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Sci/Tech'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with examples to verify model performance\n",
    "classify(peft_model, tokenizer, \"Kederis proclaims innocence Olympic champion Kostas Kederis today left hospital ahead of his date with IOC inquisitors claiming his innocence...\")\n",
    "classify(peft_model, tokenizer, \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling band of ultra-cynics, are seeing green again.\")\n",
    "classify(peft_model, tokenizer, \"Google announces new smartphone with advanced AI capabilities at annual developer conference\")\n",
    "classify(peft_model, tokenizer, \"Scientists discover potential cure for cancer in rainforest plant, clinical trials to begin next year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "2jSczJ8_ZaN3"
   },
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(inference_model, dataset, labelled=True, batch_size=8, data_collator=None):\n",
    "    \"\"\"\n",
    "    Evaluate a PEFT model on a dataset.\n",
    "    \"\"\"\n",
    "    # Create the DataLoader\n",
    "    eval_dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=data_collator)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    inference_model.to(device)\n",
    "    inference_model.eval()\n",
    "\n",
    "    all_predictions = []\n",
    "    if labelled:\n",
    "        all_labels = []\n",
    "\n",
    "    # Loop over the DataLoader\n",
    "    for batch in tqdm(eval_dataloader):\n",
    "        # Move each tensor in the batch to the device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = inference_model(**batch)\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        all_predictions.append(predictions.cpu())\n",
    "\n",
    "        if labelled:\n",
    "            # Expecting that labels are provided under the \"labels\" key.\n",
    "            references = batch[\"labels\"]\n",
    "            all_labels.append(references.cpu())\n",
    "\n",
    "    # Concatenate predictions from all batches\n",
    "    all_predictions = torch.cat(all_predictions, dim=0)\n",
    "\n",
    "    if labelled:\n",
    "        all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(all_labels.numpy(), all_predictions.numpy())\n",
    "        precision = precision_score(all_labels.numpy(), all_predictions.numpy(), average='weighted')\n",
    "        recall = recall_score(all_labels.numpy(), all_predictions.numpy(), average='weighted')\n",
    "        f1 = f1_score(all_labels.numpy(), all_predictions.numpy(), average='weighted')\n",
    "\n",
    "        # Create confusion matrix\n",
    "        cm = confusion_matrix(all_labels.numpy(), all_predictions.numpy())\n",
    "\n",
    "        # Plot confusion matrix\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(\n",
    "            cm,\n",
    "            annot=True,\n",
    "            fmt='d',\n",
    "            cmap='Blues',\n",
    "            xticklabels=[id2label[i] for i in range(len(id2label))],\n",
    "            yticklabels=[id2label[i] for i in range(len(id2label))]\n",
    "        )\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"Evaluation Metrics:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1\n",
    "        }, all_predictions\n",
    "    else:\n",
    "        return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 698
    },
    "id": "jgPxeocNZfUK",
    "outputId": "113ad366-18bc-4ced-f118-d7b1ac802666"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:03<00:00,  5.90it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.9328\n",
      "Precision: 0.9326\n",
      "Recall: 0.9328\n",
      "F1 Score: 0.9327\n",
      "\n",
      "Validation accuracy: 0.9328\n"
     ]
    }
   ],
   "source": [
    "# Check evaluation accuracy on validation set\n",
    "eval_metrics, _ = evaluate_model(peft_model, eval_dataset, True, 32, data_collator)\n",
    "print(f\"\\nValidation accuracy: {eval_metrics['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319,
     "referenced_widgets": [
      "f8d3b5ace5f34f27b8c7cbf1b87bf02b",
      "26928a4a39694e9983aa01bd167113a3",
      "5c630e1e350041999a40e559fe2f2ba4",
      "738e6d37a3414511a88934873a54572c",
      "7525803c7f43408eb6911e31f37b01fa",
      "5839fccf92bc437985714c28c7e38a96",
      "c02e50ea22d741068a4168e7af8ccbf6",
      "eb70e3dca1224312a9925c97b39ee94e",
      "643795bdca264224943cac921597f4c6",
      "051c9335ab3341869442609d1ddd924d",
      "6e2fc744cc114370838c7589dc56b0a9"
     ]
    },
    "id": "r047mhyTZh3u",
    "outputId": "5c0401dd-74b0-43ec-cae8-65ddbe11d657"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing unlabelled test data...\n",
      "Unlabelled dataset keys: ['text']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d3b5ace5f34f27b8c7cbf1b87bf02b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8000 unlabelled test samples\n",
      "Running inference on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:29<00:00,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference complete. Predictions saved to results/inference_output.csv\n",
      "\n",
      "Sample predictions:\n",
      "Sample 0: Predicted class: 3 (Sci/Tech)\n",
      "Sample 1: Predicted class: 0 (World)\n",
      "Sample 2: Predicted class: 0 (World)\n",
      "Sample 3: Predicted class: 3 (Sci/Tech)\n",
      "Sample 4: Predicted class: 1 (Sports)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Process unlabelled test data\n",
    "try:\n",
    "    print(\"\\nProcessing unlabelled test data...\")\n",
    "    unlabelled_dataset = pd.read_pickle(\"test_unlabelled.pkl\")\n",
    "\n",
    "    # For unlabelled dataset, check its structure\n",
    "    print(f\"Unlabelled dataset keys: {unlabelled_dataset.column_names if hasattr(unlabelled_dataset, 'column_names') else 'N/A'}\")\n",
    "\n",
    "    # If it's a pandas DataFrame, convert to HF Dataset\n",
    "    if isinstance(unlabelled_dataset, pd.DataFrame):\n",
    "        print(\"Converting DataFrame to Dataset\")\n",
    "        unlabelled_dataset = Dataset.from_pandas(unlabelled_dataset)\n",
    "\n",
    "    # Preprocess the test data the same way as training data\n",
    "    test_dataset = unlabelled_dataset.map(preprocess, batched=True, remove_columns=[\"text\"])\n",
    "    print(f\"Loaded {len(test_dataset)} unlabelled test samples\")\n",
    "\n",
    "    # Run inference and save predictions\n",
    "    print(\"Running inference on test dataset...\")\n",
    "    preds = evaluate_model(peft_model, test_dataset, False, 32, data_collator)\n",
    "\n",
    "    df_output = pd.DataFrame({\n",
    "        'ID': range(len(preds)),\n",
    "        'Label': preds.numpy()  # Convert to numpy for saving\n",
    "    })\n",
    "\n",
    "    # Save predictions to CSV for submission\n",
    "    submission_path = os.path.join(output_dir, \"inference_output.csv\")\n",
    "    df_output.to_csv(submission_path, index=False)\n",
    "    print(f\"Inference complete. Predictions saved to {submission_path}\")\n",
    "\n",
    "    # Check the first few predictions\n",
    "    print(\"\\nSample predictions:\")\n",
    "    for i in range(min(5, len(df_output))):\n",
    "        pred_class = df_output['Label'][i]\n",
    "        print(f\"Sample {i}: Predicted class: {pred_class} ({id2label[pred_class]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing unlabelled test data: {e}\")\n",
    "    print(\"Skipping test data processing - you'll need to rerun this section when you have the test data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uroUadnTZoT9",
    "outputId": "b6e9771d-c65a-4104-822a-d5eb1759ffd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model Parameters:\n",
      "Total parameters: 125,629,448\n",
      "Trainable parameters: 980,740\n",
      "Percentage of parameters that are trainable: 0.78%\n",
      "Under 1M parameter limit: Yes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Final parameter check\n",
    "final_trainable_params, final_all_params = count_trainable_parameters(peft_model)\n",
    "print(\"\\nFinal Model Parameters:\")\n",
    "print(f\"Total parameters: {final_all_params:,}\")\n",
    "print(f\"Trainable parameters: {final_trainable_params:,}\")\n",
    "print(f\"Percentage of parameters that are trainable: {100 * final_trainable_params / final_all_params:.2f}%\")\n",
    "print(f\"Under 1M parameter limit: {'Yes' if final_trainable_params <= 1_000_000 else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sp3-TdEAZrJi",
    "outputId": "e2e50b60-c9ab-4143-f8f9-14877c198043"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved to results/final_model\n",
      "\n",
      "Training and evaluation complete! The model is ready for submission.\n",
      "Final accuracy: 0.9328\n",
      "The model uses 980,740 trainable parameters (limit: 1,000,000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the final model\n",
    "final_model_path = os.path.join(output_dir, \"final_model\")\n",
    "peft_lora_finetuning_trainer.save_model(final_model_path)\n",
    "print(f\"Final model saved to {final_model_path}\")\n",
    "\n",
    "print(\"\\nTraining and evaluation complete! The model is ready for submission.\")\n",
    "print(f\"Final accuracy: {eval_metrics['accuracy']:.4f}\")\n",
    "print(f\"The model uses {final_trainable_params:,} trainable parameters (limit: 1,000,000)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N9E5cU0IVv1j"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.11.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c5f29ab0bd70a3fdfe3350be4806661ff87a7ec1a414855bb5824b269ce85de1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
